# ─────────────────────────────────────────────────────────────────────────────
# SAGE OS — Copyright (c) 2025 Ashish Vasant Yesale (ashishyesale007@gmail.com)
# SPDX-License-Identifier: BSD-3-Clause OR Proprietary
# SAGE OS is dual-licensed under the BSD 3-Clause License and a Commercial License.
# 
# This file is part of the SAGE OS Project.
# 
# ─────────────────────────────────────────────────────────────────────────────

name: Documentation Pages Update

on:
  push:
    branches: [ main, dev, develop ]
    paths:
      - 'docs/**'
      - 'kernel/**'
      - 'boot/**'
      - 'drivers/**'
      - 'scripts/**'
      - 'mkdocs.yml'
      - '*.md'
  pull_request:
    branches: [ main, dev ]
    paths:
      - 'docs/**'
      - 'mkdocs.yml'
  workflow_dispatch:
    inputs:
      force_rebuild:
        description: 'Force complete documentation rebuild'
        required: false
        default: 'false'
        type: boolean
      update_diagrams:
        description: 'Update all diagrams and visualizations'
        required: false
        default: 'true'
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # Analyze codebase and generate documentation
  analyze-codebase:
    name: Analyze Codebase
    runs-on: ubuntu-latest
    outputs:
      files-changed: ${{ steps.changes.outputs.files }}
      docs-updated: ${{ steps.changes.outputs.docs }}
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Detect Changes
      id: changes
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ github.event.inputs.force_rebuild }}" = "true" ]; then
          echo "files=all" >> $GITHUB_OUTPUT
          echo "docs=true" >> $GITHUB_OUTPUT
        else
          CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          echo "files=${CHANGED_FILES}" >> $GITHUB_OUTPUT
          
          if echo "${CHANGED_FILES}" | grep -E "(docs/|mkdocs\.yml|\.md$)"; then
            echo "docs=true" >> $GITHUB_OUTPUT
          else
            echo "docs=false" >> $GITHUB_OUTPUT
          fi
        fi

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Analysis Tools
      run: |
        pip install --upgrade pip
        pip install pygments
        sudo apt-get update
        sudo apt-get install -y cloc tree || true

    - name: Analyze Code Structure
      run: |
        echo "# Code Analysis Report" > code-analysis.md
        echo "Generated on: $(date)" >> code-analysis.md
        echo "" >> code-analysis.md
        
        echo "## File Count by Type" >> code-analysis.md
        cloc --md . >> code-analysis.md
        
        echo "" >> code-analysis.md
        echo "## Directory Structure" >> code-analysis.md
        echo '```' >> code-analysis.md
        tree -I '__pycache__|*.pyc|build|dist|site' >> code-analysis.md
        echo '```' >> code-analysis.md
        
        echo "" >> code-analysis.md
        echo "## Code Complexity" >> code-analysis.md
        echo "Code complexity analysis completed" >> code-analysis.md

    - name: Generate File Relationships
      run: |
        python3 << 'EOF'
        import os
        import re
        import json
        from pathlib import Path

        def analyze_includes(file_path):
            """Analyze #include statements in C files"""
            includes = []
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    # Find #include statements
                    include_pattern = r'#include\s*[<"](.*?)[>"]'
                    includes = re.findall(include_pattern, content)
            except:
                pass
            return includes

        def analyze_dependencies():
            """Analyze file dependencies"""
            dependencies = {}
            
            for root, dirs, files in os.walk('.'):
                # Skip certain directories
                if any(skip in root for skip in ['.git', 'build', 'dist', 'site', '__pycache__']):
                    continue
                    
                for file in files:
                    if file.endswith(('.c', '.h', '.S')):
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path)
                        includes = analyze_includes(file_path)
                        dependencies[rel_path] = {
                            'includes': includes,
                            'size': os.path.getsize(file_path),
                            'type': file.split('.')[-1]
                        }
            
            return dependencies

        # Generate dependency analysis
        deps = analyze_dependencies()
        
        with open('file-dependencies.json', 'w') as f:
            json.dump(deps, f, indent=2)
        
        # Generate Mermaid diagram
        with open('dependency-diagram.md', 'w') as f:
            f.write("# File Dependency Diagram\n\n")
            f.write("```mermaid\n")
            f.write("graph TD\n")
            
            for file, info in deps.items():
                if info['type'] in ['c', 'h']:
                    clean_name = file.replace('/', '_').replace('.', '_')
                    f.write(f'    {clean_name}["{file}"]\n')
                    
                    for include in info['includes']:
                        if include.endswith(('.h', '.c')):
                            include_clean = include.replace('/', '_').replace('.', '_')
                            f.write(f'    {clean_name} --> {include_clean}\n')
            
            f.write("```\n")
        EOF

    - name: Upload Analysis Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: code-analysis
        path: |
          code-analysis.md
          file-dependencies.json
          dependency-diagram.md
        retention-days: 30

  # Generate comprehensive documentation
  generate-documentation:
    name: Generate Documentation
    runs-on: ubuntu-latest
    needs: analyze-codebase
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Install Documentation Dependencies
      run: |
        pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocs-mermaid2-plugin
        pip install mkdocstrings mkdocstrings-python
        pip install mkdocs-git-revision-date-localized-plugin
        pip install mkdocs-minify-plugin
        pip install mkdocs-macros-plugin
        pip install pymdown-extensions
        
        # Install PlantUML for advanced diagrams
        sudo apt-get update
        sudo apt-get install -y default-jre
        wget -O plantuml.jar http://sourceforge.net/projects/plantuml/files/plantuml.jar/download
        
        # Install Mermaid CLI for diagram generation
        npm install -g @mermaid-js/mermaid-cli

    - name: Download Analysis Artifacts
      uses: actions/download-artifact@v4
      with:
        name: code-analysis
        path: analysis/

    - name: Generate API Documentation
      run: |
        python3 << 'EOF'
        import os
        import re
        from pathlib import Path

        def extract_functions(file_path):
            """Extract function definitions from C files"""
            functions = []
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # Pattern for C function definitions
                    func_pattern = r'(\w+\s+\**\w+\s*\([^)]*\)\s*\{)'
                    matches = re.finditer(func_pattern, content, re.MULTILINE)
                    
                    for match in matches:
                        func_def = match.group(1).replace('{', '').strip()
                        functions.append(func_def)
            except:
                pass
            return functions

        def generate_api_docs():
            """Generate API documentation"""
            api_docs = {}
            
            for root, dirs, files in os.walk('.'):
                if any(skip in root for skip in ['.git', 'build', 'dist', 'site']):
                    continue
                    
                for file in files:
                    if file.endswith('.c'):
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path)
                        functions = extract_functions(file_path)
                        
                        if functions:
                            api_docs[rel_path] = functions
            
            # Generate markdown documentation
            os.makedirs('docs/api/generated', exist_ok=True)
            
            with open('docs/api/generated/functions.md', 'w') as f:
                f.write("# Function Reference\n\n")
                f.write("Auto-generated function documentation.\n\n")
                
                for file, functions in api_docs.items():
                    f.write(f"## {file}\n\n")
                    for func in functions:
                        f.write(f"### `{func}`\n\n")
                        f.write("*Documentation to be added*\n\n")

        generate_api_docs()
        EOF

    - name: Update File Analysis Documentation
      run: |
        # Copy analysis results to docs
        cp analysis/code-analysis.md docs/files/
        cp analysis/dependency-diagram.md docs/diagrams/
        
        # Update file metrics
        python3 << 'EOF'
        import os
        import json
        from datetime import datetime

        # Load dependency data
        with open('analysis/file-dependencies.json', 'r') as f:
            deps = json.load(f)

        # Generate file metrics page
        with open('docs/files/metrics.md', 'w') as f:
            f.write("# File Metrics and Statistics\n\n")
            f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## File Size Distribution\n\n")
            f.write("| File | Size (bytes) | Type | Includes |\n")
            f.write("|------|-------------|------|----------|\n")
            
            for file, info in sorted(deps.items(), key=lambda x: x[1]['size'], reverse=True):
                includes_count = len(info['includes'])
                f.write(f"| {file} | {info['size']} | {info['type']} | {includes_count} |\n")
            
            f.write("\n## Dependency Statistics\n\n")
            total_files = len(deps)
            total_includes = sum(len(info['includes']) for info in deps.values())
            avg_includes = total_includes / total_files if total_files > 0 else 0
            
            f.write(f"- Total files analyzed: {total_files}\n")
            f.write(f"- Total include statements: {total_includes}\n")
            f.write(f"- Average includes per file: {avg_includes:.2f}\n")
        EOF

    - name: Generate Sequence Diagrams
      if: github.event.inputs.update_diagrams == 'true' || github.event.inputs.update_diagrams == ''
      run: |
        mkdir -p docs/diagrams/sequences
        
        # Generate boot sequence diagram
        cat > docs/diagrams/sequences/boot-sequence.md << 'EOF'
        # Boot Sequence Diagrams

        ## System Boot Process

        ```mermaid
        sequenceDiagram
            participant BIOS as BIOS/UEFI
            participant Boot as Bootloader
            participant Kernel as Kernel
            participant Memory as Memory Manager
            participant Drivers as Device Drivers
            participant Shell as Shell
            participant AI as AI Engine

            BIOS->>Boot: Power On Self Test
            Boot->>Boot: Load from storage
            Boot->>Memory: Initialize memory map
            Boot->>Kernel: Transfer control

            Kernel->>Memory: Setup virtual memory
            Kernel->>Drivers: Initialize drivers
            Kernel->>Shell: Start shell process
            Kernel->>AI: Initialize AI subsystem

            Shell->>Shell: Display prompt
            AI->>AI: Load models
            AI->>Kernel: Register optimization hooks

            Note over BIOS,AI: System ready for operation
        ```

        ## Memory Allocation Sequence

        ```mermaid
        sequenceDiagram
            participant App as Application
            participant Kernel as Kernel
            participant MM as Memory Manager
            participant PMM as Physical Memory Manager
            participant VMM as Virtual Memory Manager

            App->>Kernel: malloc(size)
            Kernel->>MM: kmalloc(size)
            MM->>MM: Check heap availability
            
            alt Heap has space
                MM->>MM: Allocate from heap
                MM->>Kernel: Return pointer
            else Need new pages
                MM->>PMM: Allocate physical pages
                PMM->>VMM: Map virtual pages
                VMM->>MM: Return mapped address
                MM->>Kernel: Return pointer
            end
            
            Kernel->>App: Return allocated memory
        ```
        EOF

        # Generate driver interaction diagram
        cat > docs/diagrams/sequences/driver-interaction.md << 'EOF'
        # Driver Interaction Diagrams

        ## UART Driver Communication

        ```mermaid
        sequenceDiagram
            participant App as Application
            participant Kernel as Kernel
            participant UART as UART Driver
            participant HW as Hardware

            App->>Kernel: write(fd, data, len)
            Kernel->>UART: uart_write(data, len)
            
            loop For each byte
                UART->>HW: Check TX ready
                HW->>UART: TX ready status
                UART->>HW: Write byte to TX register
            end
            
            UART->>Kernel: Bytes written
            Kernel->>App: Return count
        ```

        ## I2C Transaction Sequence

        ```mermaid
        sequenceDiagram
            participant Driver as I2C Driver
            participant Controller as I2C Controller
            participant Device as I2C Device

            Driver->>Controller: Send START condition
            Driver->>Controller: Send device address
            Controller->>Device: Address + R/W bit
            Device->>Controller: ACK
            Controller->>Driver: ACK received

            loop Data transfer
                Driver->>Controller: Send/Receive data byte
                Controller->>Device: Data byte
                Device->>Controller: ACK/Data
                Controller->>Driver: ACK/Data received
            end

            Driver->>Controller: Send STOP condition
        ```
        EOF

    - name: Generate Class Diagrams
      run: |
        mkdir -p docs/diagrams/classes
        
        cat > docs/diagrams/classes/kernel-classes.md << 'EOF'
        # Kernel Class Diagrams

        ## Core Kernel Classes

        ```mermaid
        classDiagram
            class KernelCore {
                -interrupt_table[]
                -system_call_table[]
                -scheduler_state
                +kernel_main()
                +handle_interrupt(int_num)
                +system_call_handler(call_num, args)
                +panic(message)
                +schedule_next_process()
                -init_subsystems()
                -setup_interrupts()
            }

            class MemoryManager {
                -page_directory*
                -free_page_list[]
                -heap_start
                -heap_end
                -total_memory
                +allocate_page()
                +free_page(page*)
                +map_virtual(virt_addr, phys_addr)
                +unmap_virtual(virt_addr)
                +kmalloc(size)
                +kfree(ptr)
                +get_memory_stats()
                -setup_paging()
                -expand_heap()
            }

            class ProcessManager {
                -current_process*
                -process_list[]
                -ready_queue[]
                -blocked_queue[]
                -next_pid
                +create_process(entry_point, args)
                +destroy_process(pid)
                +schedule()
                +context_switch(new_process*)
                +block_process(pid, reason)
                +unblock_process(pid)
                +yield()
                -save_context(process*)
                -restore_context(process*)
            }

            class FileSystem {
                -root_inode*
                -mount_points[]
                -open_files[]
                -file_cache[]
                +open(path, mode)
                +close(fd)
                +read(fd, buffer, size)
                +write(fd, buffer, size)
                +seek(fd, offset, whence)
                +mkdir(path, mode)
                +rmdir(path)
                +stat(path, stat_buf)
                -resolve_path(path)
                -allocate_inode()
            }

            class DeviceManager {
                -device_list[]
                -driver_registry[]
                -interrupt_handlers[]
                +register_device(device*)
                +unregister_device(device_id)
                +register_driver(driver*)
                +find_driver(device_type)
                +device_open(device_id, mode)
                +device_close(device_id)
                +device_read(device_id, buffer, size)
                +device_write(device_id, buffer, size)
                +device_ioctl(device_id, cmd, arg)
                -match_driver_device(driver*, device*)
            }

            KernelCore --> MemoryManager : manages
            KernelCore --> ProcessManager : schedules
            KernelCore --> FileSystem : provides
            KernelCore --> DeviceManager : controls
            MemoryManager --> ProcessManager : allocates for
            ProcessManager --> FileSystem : accesses
            DeviceManager --> FileSystem : storage devices
        ```

        ## Driver Framework Classes

        ```mermaid
        classDiagram
            class Driver {
                <<interface>>
                +init(config*)
                +cleanup()
                +open(mode)
                +close()
                +read(buffer, size)
                +write(buffer, size)
                +ioctl(cmd, arg)
                +get_status()
            }

            class UARTDriver {
                -base_address
                -baud_rate
                -data_bits
                -stop_bits
                -parity
                -tx_buffer[]
                -rx_buffer[]
                +init(config*)
                +set_baud_rate(rate)
                +configure_format(data_bits, stop_bits, parity)
                +enable_interrupts()
                +disable_interrupts()
                -configure_pins()
                -setup_clock()
            }

            class I2CDriver {
                -bus_number
                -clock_speed
                -slave_addresses[]
                -transaction_queue[]
                +init(config*)
                +scan_bus()
                +set_slave_address(addr)
                +start_transaction()
                +stop_transaction()
                +send_byte(data)
                +receive_byte()
                -wait_for_ack()
                -handle_arbitration_lost()
            }

            class SPIDriver {
                -spi_port
                -clock_polarity
                -clock_phase
                -bit_order
                -chip_select_pins[]
                +init(config*)
                +configure_spi(config*)
                +select_device(device_id)
                +deselect_device(device_id)
                +transfer_byte(data)
                +transfer_buffer(tx_buf, rx_buf, len)
                -setup_dma()
                -wait_transfer_complete()
            }

            Driver <|-- UARTDriver : implements
            Driver <|-- I2CDriver : implements
            Driver <|-- SPIDriver : implements
        ```
        EOF

    - name: Build Documentation Site
      run: |
        # Validate mkdocs configuration
        mkdocs build --strict --verbose
        
        # Generate site statistics
        echo "# Documentation Build Statistics" > docs/build-stats.md
        echo "" >> docs/build-stats.md
        echo "Build completed on: $(date)" >> docs/build-stats.md
        echo "Total pages: $(find site -name '*.html' | wc -l)" >> docs/build-stats.md
        echo "Total size: $(du -sh site | cut -f1)" >> docs/build-stats.md

    - name: Validate Documentation
      run: |
        # Check for broken links
        python3 << 'EOF'
        import os
        import re
        from pathlib import Path

        def check_internal_links():
            """Check for broken internal links in markdown files"""
            broken_links = []
            
            for md_file in Path('docs').rglob('*.md'):
                with open(md_file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # Find markdown links
                    link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
                    links = re.findall(link_pattern, content)
                    
                    for text, link in links:
                        if link.startswith('http'):
                            continue  # Skip external links
                        
                        # Check if file exists
                        if link.startswith('/'):
                            target_path = Path('docs' + link)
                        else:
                            target_path = md_file.parent / link
                        
                        if not target_path.exists():
                            broken_links.append(f"{md_file}: {link}")
            
            if broken_links:
                print("Broken internal links found:")
                for link in broken_links:
                    print(f"  - {link}")
                return False
            else:
                print("All internal links are valid")
                return True

        check_internal_links()
        EOF

    - name: Upload Documentation Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: documentation-site
        path: site/
        retention-days: 30

    - name: Upload Documentation Source
      uses: actions/upload-artifact@v4
      with:
        name: documentation-source
        path: |
          docs/
          mkdocs.yml
        retention-days: 30

  # Deploy to GitHub Pages
  deploy-pages:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    needs: [analyze-codebase, generate-documentation]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev'
    
    permissions:
      contents: read
      pages: write
      id-token: write
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Download Documentation Site
      uses: actions/download-artifact@v4
      with:
        name: documentation-site
        path: site/

    - name: Setup Pages
      uses: actions/configure-pages@v4

    - name: Upload to GitHub Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: site/

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4

  # Create documentation summary
  documentation-summary:
    name: Documentation Summary
    runs-on: ubuntu-latest
    needs: [analyze-codebase, generate-documentation]
    if: always()
    
    steps:
    - name: Download Analysis Artifacts
      uses: actions/download-artifact@v4
      with:
        name: code-analysis
        path: analysis/

    - name: Create Summary
      run: |
        echo "## 📚 Documentation Update Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.generate-documentation.result }}" == "success" ]; then
          echo "✅ **Documentation build successful**" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Documentation build failed**" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📊 Code Analysis Results" >> $GITHUB_STEP_SUMMARY
        
        if [ -f analysis/code-analysis.md ]; then
          echo "- Code analysis completed" >> $GITHUB_STEP_SUMMARY
          echo "- File dependency graph generated" >> $GITHUB_STEP_SUMMARY
          echo "- API documentation updated" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 🔗 Generated Documentation" >> $GITHUB_STEP_SUMMARY
        echo "- System architecture diagrams" >> $GITHUB_STEP_SUMMARY
        echo "- Sequence diagrams for boot and driver interactions" >> $GITHUB_STEP_SUMMARY
        echo "- Class diagrams for kernel components" >> $GITHUB_STEP_SUMMARY
        echo "- Deep file analysis with relationships" >> $GITHUB_STEP_SUMMARY
        echo "- API reference documentation" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ github.ref }}" == "refs/heads/main" ] || [ "${{ github.ref }}" == "refs/heads/dev" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🚀 Deployment" >> $GITHUB_STEP_SUMMARY
          echo "Documentation deployed to GitHub Pages" >> $GITHUB_STEP_SUMMARY
        fi