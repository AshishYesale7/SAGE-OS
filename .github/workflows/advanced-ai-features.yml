name: üöÄ Advanced AI Features for SAGE OS

on:
  workflow_dispatch:
    inputs:
      feature_type:
        description: 'Advanced AI Feature to Run'
        required: true
        type: choice
        options:
          - 'multi-model-comparison'
          - 'code-quality-analysis'
          - 'security-audit'
          - 'performance-optimization'
          - 'documentation-quality-check'
          - 'ai-powered-testing'
          - 'architecture-review'
          - 'dependency-analysis'
          - 'all-features'
      primary_model:
        description: 'Primary AI Model'
        required: false
        default: 'openai/gpt-4o-mini'
        type: choice
        options:
          - 'openai/gpt-4.1'
          - 'openai/gpt-4.1-mini'
          - 'openai/gpt-4o'
          - 'openai/gpt-4o-mini'
          - 'microsoft/phi-4'
          - 'meta/llama-3.3-70b-instruct'
          - 'mistral-ai/codestral-2501'
          - 'deepseek/deepseek-v3-0324'
      comparison_model:
        description: 'Comparison AI Model (for multi-model features)'
        required: false
        default: 'microsoft/phi-4'
        type: choice
        options:
          - 'openai/gpt-4.1'
          - 'microsoft/phi-4'
          - 'meta/llama-3.3-70b-instruct'
          - 'mistral-ai/codestral-2501'
          - 'deepseek/deepseek-v3-0324'
          - 'xai/grok-3-mini'

permissions:
  contents: write
  models: read
  id-token: write
  issues: write
  pull-requests: write

jobs:
  advanced-ai-features:
    name: üöÄ Advanced AI Features
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: üì• Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: üêç Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: üì¶ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests markdown beautifulsoup4 pyyaml numpy pandas matplotlib seaborn plotly
        pip install ast-grep bandit safety semgrep
        
    - name: üöÄ Run Advanced AI Features
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        FEATURE_TYPE: ${{ github.event.inputs.feature_type }}
        PRIMARY_MODEL: ${{ github.event.inputs.primary_model }}
        COMPARISON_MODEL: ${{ github.event.inputs.comparison_model }}
      run: |
        echo "üöÄ Running Advanced AI Feature: $FEATURE_TYPE"
        echo "ü§ñ Primary Model: $PRIMARY_MODEL"
        echo "üîÑ Comparison Model: $COMPARISON_MODEL"
        
        # Create advanced features directory
        mkdir -p docs/ai-advanced
        
        python3 << 'EOF'
        import os
        import json
        import requests
        import subprocess
        import ast
        import re
        from datetime import datetime
        from pathlib import Path
        
        # Configuration
        GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')
        FEATURE_TYPE = os.environ.get('FEATURE_TYPE')
        PRIMARY_MODEL = os.environ.get('PRIMARY_MODEL')
        COMPARISON_MODEL = os.environ.get('COMPARISON_MODEL')
        API_BASE = 'https://models.inference.ai.azure.com'
        
        def call_ai_model(prompt, model_id, max_tokens=3000):
            """Call GitHub Models API"""
            headers = {
                'Authorization': f'Bearer {GITHUB_TOKEN}',
                'Content-Type': 'application/json',
                'api-version': '2024-08-01-preview'
            }
            
            data = {
                'model': model_id,
                'messages': [
                    {
                        'role': 'system',
                        'content': 'You are an expert software engineer and AI assistant specializing in operating systems, security, and code quality analysis.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': max_tokens,
                'temperature': 0.2
            }
            
            try:
                response = requests.post(f'{API_BASE}/chat/completions', 
                                       headers=headers, 
                                       json=data, 
                                       timeout=60)
                response.raise_for_status()
                result = response.json()
                return result['choices'][0]['message']['content']
            except Exception as e:
                return f"Error with {model_id}: {str(e)}"
        
        def get_source_files():
            """Get all source files in the project"""
            source_files = []
            for root, dirs, files in os.walk('.'):
                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['build', 'node_modules', '__pycache__']]
                for file in files:
                    if file.endswith(('.c', '.h', '.py', '.rs', '.cpp', '.hpp', '.s', '.S', '.asm')):
                        filepath = os.path.join(root, file)
                        try:
                            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                            source_files.append({
                                'path': filepath,
                                'content': content,
                                'size': len(content),
                                'lines': len(content.splitlines()),
                                'language': filepath.split('.')[-1]
                            })
                        except:
                            continue
            return source_files
        
        def multi_model_comparison():
            """Compare multiple AI models on the same task"""
            print("üîÑ Running Multi-Model Comparison...")
            
            source_files = get_source_files()
            sample_code = source_files[0]['content'][:2000] if source_files else "No source code found"
            
            prompt = f"""
            Analyze this SAGE OS kernel code and provide:
            1. Code quality assessment (1-10 scale)
            2. Security vulnerabilities found
            3. Performance optimization suggestions
            4. Architecture improvements
            5. Overall recommendations
            
            Code to analyze:
            ```c
            {sample_code}
            ```
            
            Provide a structured analysis with specific, actionable recommendations.
            """
            
            models = [PRIMARY_MODEL, COMPARISON_MODEL, 'openai/gpt-4o-mini']
            results = {}
            
            for model in models:
                print(f"  ü§ñ Analyzing with {model}...")
                analysis = call_ai_model(prompt, model)
                results[model] = analysis
            
            # Generate comparison report
            comparison_prompt = f"""
            Compare these AI model analyses of SAGE OS code and create a comprehensive comparison report:
            
            {chr(10).join([f"## Analysis by {model}:{chr(10)}{analysis}{chr(10)}" for model, analysis in results.items()])}
            
            Create a detailed comparison including:
            1. Consensus findings (what all models agree on)
            2. Unique insights from each model
            3. Quality and depth comparison
            4. Recommended actions based on combined analysis
            5. Model performance ranking for this task
            
            Format as a professional technical report.
            """
            
            comparison_report = call_ai_model(comparison_prompt, PRIMARY_MODEL, max_tokens=4000)
            
            with open('docs/ai-advanced/multi-model-comparison.md', 'w') as f:
                f.write(f"# üîÑ Multi-Model AI Comparison Report\\n\\n")
                f.write(f"**Generated**: {datetime.now().isoformat()}\\n")
                f.write(f"**Models Compared**: {', '.join(models)}\\n\\n")
                f.write("## Individual Model Analyses\\n\\n")
                
                for model, analysis in results.items():
                    f.write(f"### {model}\\n\\n{analysis}\\n\\n")
                
                f.write("## Comparative Analysis\\n\\n")
                f.write(comparison_report)
            
            return results
        
        def code_quality_analysis():
            """Advanced code quality analysis using AI"""
            print("üìä Running Code Quality Analysis...")
            
            source_files = get_source_files()
            
            # Analyze each file
            quality_reports = []
            for file_info in source_files[:10]:  # Limit to first 10 files
                prompt = f"""
                Perform a comprehensive code quality analysis of this {file_info['language']} file:
                
                File: {file_info['path']}
                Lines: {file_info['lines']}
                
                Code:
                ```{file_info['language']}
                {file_info['content'][:3000]}
                ```
                
                Analyze:
                1. Code complexity and maintainability
                2. Naming conventions and readability
                3. Error handling and robustness
                4. Memory management (if applicable)
                5. Performance considerations
                6. Security implications
                7. Documentation quality
                8. Testing coverage potential
                
                Provide specific scores (1-10) for each category and detailed recommendations.
                """
                
                analysis = call_ai_model(prompt, PRIMARY_MODEL)
                quality_reports.append({
                    'file': file_info['path'],
                    'analysis': analysis
                })
            
            # Generate summary report
            summary_prompt = f"""
            Create a comprehensive code quality summary report for SAGE OS based on these individual file analyses:
            
            {chr(10).join([f"File: {report['file']}{chr(10)}{report['analysis']}{chr(10)}" for report in quality_reports])}
            
            Generate:
            1. Overall quality score and ranking
            2. Top 5 critical issues to address
            3. Quality improvement roadmap
            4. Best practices recommendations
            5. Automated tooling suggestions
            6. Metrics and KPIs to track
            
            Format as an executive summary with actionable insights.
            """
            
            summary = call_ai_model(summary_prompt, PRIMARY_MODEL, max_tokens=4000)
            
            with open('docs/ai-advanced/code-quality-analysis.md', 'w') as f:
                f.write(f"# üìä Code Quality Analysis Report\\n\\n")
                f.write(f"**Generated**: {datetime.now().isoformat()}\\n")
                f.write(f"**Model**: {PRIMARY_MODEL}\\n")
                f.write(f"**Files Analyzed**: {len(quality_reports)}\\n\\n")
                f.write("## Executive Summary\\n\\n")
                f.write(summary)
                f.write("\\n\\n## Individual File Analyses\\n\\n")
                
                for report in quality_reports:
                    f.write(f"### {report['file']}\\n\\n{report['analysis']}\\n\\n")
        
        def security_audit():
            """AI-powered security audit"""
            print("üîí Running Security Audit...")
            
            source_files = get_source_files()
            
            # Security-focused analysis
            security_issues = []
            for file_info in source_files:
                if file_info['language'] in ['c', 'h', 'cpp', 'hpp']:
                    prompt = f"""
                    Perform a comprehensive security audit of this kernel code:
                    
                    File: {file_info['path']}
                    
                    Code:
                    ```c
                    {file_info['content'][:2000]}
                    ```
                    
                    Look for:
                    1. Buffer overflow vulnerabilities
                    2. Integer overflow/underflow
                    3. Use-after-free bugs
                    4. Race conditions
                    5. Privilege escalation risks
                    6. Input validation issues
                    7. Memory leaks
                    8. Unsafe function usage
                    9. Cryptographic weaknesses
                    10. Side-channel vulnerabilities
                    
                    For each issue found, provide:
                    - Severity level (Critical/High/Medium/Low)
                    - Exact location (line numbers if possible)
                    - Exploitation scenario
                    - Mitigation strategy
                    """
                    
                    analysis = call_ai_model(prompt, PRIMARY_MODEL)
                    security_issues.append({
                        'file': file_info['path'],
                        'analysis': analysis
                    })
            
            # Generate security report
            security_prompt = f"""
            Create a comprehensive security audit report for SAGE OS based on these analyses:
            
            {chr(10).join([f"File: {issue['file']}{chr(10)}{issue['analysis']}{chr(10)}" for issue in security_issues])}
            
            Generate:
            1. Executive summary with risk assessment
            2. Critical vulnerabilities requiring immediate attention
            3. Security hardening recommendations
            4. Secure coding guidelines for the team
            5. Security testing strategy
            6. Compliance considerations
            7. Incident response procedures
            
            Format as a professional security audit report.
            """
            
            security_report = call_ai_model(security_prompt, PRIMARY_MODEL, max_tokens=4000)
            
            with open('docs/ai-advanced/security-audit.md', 'w') as f:
                f.write(f"# üîí Security Audit Report\\n\\n")
                f.write(f"**Generated**: {datetime.now().isoformat()}\\n")
                f.write(f"**Model**: {PRIMARY_MODEL}\\n")
                f.write(f"**Files Audited**: {len(security_issues)}\\n\\n")
                f.write("## Security Assessment\\n\\n")
                f.write(security_report)
                f.write("\\n\\n## Detailed Findings\\n\\n")
                
                for issue in security_issues:
                    f.write(f"### {issue['file']}\\n\\n{issue['analysis']}\\n\\n")
        
        def performance_optimization():
            """AI-powered performance optimization analysis"""
            print("‚ö° Running Performance Optimization Analysis...")
            
            source_files = get_source_files()
            
            perf_analyses = []
            for file_info in source_files[:8]:  # Focus on key files
                prompt = f"""
                Analyze this code for performance optimization opportunities:
                
                File: {file_info['path']}
                Language: {file_info['language']}
                
                Code:
                ```{file_info['language']}
                {file_info['content'][:2500]}
                ```
                
                Identify:
                1. CPU-intensive operations that can be optimized
                2. Memory usage patterns and optimization opportunities
                3. I/O operations that can be improved
                4. Algorithm complexity issues
                5. Cache-friendly optimizations
                6. Parallelization opportunities
                7. Compiler optimization hints
                8. Data structure improvements
                9. Hot path optimizations
                10. Resource management improvements
                
                For each optimization, provide:
                - Expected performance impact
                - Implementation difficulty
                - Code example of the optimization
                - Potential trade-offs
                """
                
                analysis = call_ai_model(prompt, PRIMARY_MODEL)
                perf_analyses.append({
                    'file': file_info['path'],
                    'analysis': analysis
                })
            
            # Generate performance report
            perf_prompt = f"""
            Create a comprehensive performance optimization report for SAGE OS:
            
            {chr(10).join([f"File: {analysis['file']}{chr(10)}{analysis['analysis']}{chr(10)}" for analysis in perf_analyses])}
            
            Generate:
            1. Performance optimization roadmap
            2. High-impact, low-effort optimizations
            3. Long-term performance strategy
            4. Benchmarking recommendations
            5. Performance monitoring strategy
            6. Resource utilization analysis
            7. Scalability considerations
            
            Prioritize optimizations by impact and implementation effort.
            """
            
            perf_report = call_ai_model(perf_prompt, PRIMARY_MODEL, max_tokens=4000)
            
            with open('docs/ai-advanced/performance-optimization.md', 'w') as f:
                f.write(f"# ‚ö° Performance Optimization Report\\n\\n")
                f.write(f"**Generated**: {datetime.now().isoformat()}\\n")
                f.write(f"**Model**: {PRIMARY_MODEL}\\n")
                f.write(f"**Files Analyzed**: {len(perf_analyses)}\\n\\n")
                f.write("## Performance Analysis\\n\\n")
                f.write(perf_report)
                f.write("\\n\\n## Detailed Optimizations\\n\\n")
                
                for analysis in perf_analyses:
                    f.write(f"### {analysis['file']}\\n\\n{analysis['analysis']}\\n\\n")
        
        def architecture_review():
            """AI-powered architecture review"""
            print("üèóÔ∏è Running Architecture Review...")
            
            source_files = get_source_files()
            
            # Analyze project structure
            structure_info = {}
            for file_info in source_files:
                dir_name = os.path.dirname(file_info['path'])
                if dir_name not in structure_info:
                    structure_info[dir_name] = []
                structure_info[dir_name].append(file_info)
            
            prompt = f"""
            Perform a comprehensive architecture review of SAGE OS:
            
            Project Structure:
            {chr(10).join([f"{dir_name}: {len(files)} files ({sum(f['lines'] for f in files)} lines)" for dir_name, files in structure_info.items()])}
            
            Key Files Analysis:
            {chr(10).join([f"- {f['path']} ({f['lines']} lines, {f['language']})" for f in source_files[:15]])}
            
            Sample Code from Key Components:
            {chr(10).join([f"File: {f['path']}{chr(10)}```{f['language']}{chr(10)}{f['content'][:800]}{chr(10)}```{chr(10)}" for f in source_files[:5]])}
            
            Analyze:
            1. Overall architecture design and patterns
            2. Module organization and separation of concerns
            3. Interface design and API consistency
            4. Dependency management and coupling
            5. Scalability and extensibility
            6. Error handling strategy
            7. Configuration management
            8. Testing architecture
            9. Documentation structure
            10. Deployment and build architecture
            
            Provide:
            - Architecture strengths and weaknesses
            - Recommended improvements
            - Design pattern suggestions
            - Refactoring opportunities
            - Future architecture evolution path
            """
            
            arch_review = call_ai_model(prompt, PRIMARY_MODEL, max_tokens=4000)
            
            with open('docs/ai-advanced/architecture-review.md', 'w') as f:
                f.write(f"# üèóÔ∏è Architecture Review Report\\n\\n")
                f.write(f"**Generated**: {datetime.now().isoformat()}\\n")
                f.write(f"**Model**: {PRIMARY_MODEL}\\n")
                f.write(f"**Total Files**: {len(source_files)}\\n")
                f.write(f"**Total Lines**: {sum(f['lines'] for f in source_files)}\\n\\n")
                f.write(arch_review)
        
        # Execute selected feature
        if FEATURE_TYPE == 'multi-model-comparison' or FEATURE_TYPE == 'all-features':
            multi_model_comparison()
            
        if FEATURE_TYPE == 'code-quality-analysis' or FEATURE_TYPE == 'all-features':
            code_quality_analysis()
            
        if FEATURE_TYPE == 'security-audit' or FEATURE_TYPE == 'all-features':
            security_audit()
            
        if FEATURE_TYPE == 'performance-optimization' or FEATURE_TYPE == 'all-features':
            performance_optimization()
            
        if FEATURE_TYPE == 'architecture-review' or FEATURE_TYPE == 'all-features':
            architecture_review()
        
        # Generate master report
        master_report = f"""# üöÄ Advanced AI Analysis Report for SAGE OS
        
        **Generated**: {datetime.now().isoformat()}
        **Feature Type**: {FEATURE_TYPE}
        **Primary Model**: {PRIMARY_MODEL}
        **Comparison Model**: {COMPARISON_MODEL}
        
        ## Analysis Summary
        
        This report contains advanced AI-powered analysis of the SAGE OS codebase using state-of-the-art language models from GitHub Models.
        
        ## Available Reports
        
        """
        
        reports = []
        if os.path.exists('docs/ai-advanced/multi-model-comparison.md'):
            reports.append("- [üîÑ Multi-Model Comparison](multi-model-comparison.md)")
        if os.path.exists('docs/ai-advanced/code-quality-analysis.md'):
            reports.append("- [üìä Code Quality Analysis](code-quality-analysis.md)")
        if os.path.exists('docs/ai-advanced/security-audit.md'):
            reports.append("- [üîí Security Audit](security-audit.md)")
        if os.path.exists('docs/ai-advanced/performance-optimization.md'):
            reports.append("- [‚ö° Performance Optimization](performance-optimization.md)")
        if os.path.exists('docs/ai-advanced/architecture-review.md'):
            reports.append("- [üèóÔ∏è Architecture Review](architecture-review.md)")
        
        master_report += chr(10).join(reports)
        master_report += f"""
        
        ## AI Models Used
        
        - **Primary Model**: {PRIMARY_MODEL}
        - **Comparison Model**: {COMPARISON_MODEL}
        - **API**: GitHub Models
        
        ## Next Steps
        
        1. Review each analysis report
        2. Prioritize recommendations by impact
        3. Create implementation plan
        4. Track progress with metrics
        
        ---
        
        *Generated by SAGE OS Advanced AI Analysis System*
        """
        
        with open('docs/ai-advanced/README.md', 'w') as f:
            f.write(master_report)
        
        print("üéâ Advanced AI analysis completed successfully!")
        EOF
        
    - name: üì§ Commit Advanced Analysis
      run: |
        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add generated files
        git add docs/ai-advanced/
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "üöÄ Advanced AI Analysis: ${{ env.FEATURE_TYPE }}

          Generated advanced AI analysis using GitHub Models:
          - Primary Model: ${{ env.PRIMARY_MODEL }}
          - Comparison Model: ${{ env.COMPARISON_MODEL }}
          - Feature Type: ${{ env.FEATURE_TYPE }}
          
          Analysis includes:
          $(find docs/ai-advanced -name "*.md" -exec basename {} \; | sort | sed 's/^/- /')
          
          Generated by: ${{ github.workflow }}
          Date: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
          
          git push
          echo "‚úÖ Advanced analysis committed and pushed"
        fi
        
    - name: üìã Update Job Summary
      run: |
        echo "## üöÄ Advanced AI Analysis Complete" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "‚úÖ **Status**: Advanced analysis completed successfully" >> $GITHUB_STEP_SUMMARY
        echo "üéØ **Feature**: ${{ env.FEATURE_TYPE }}" >> $GITHUB_STEP_SUMMARY
        echo "ü§ñ **Primary Model**: ${{ env.PRIMARY_MODEL }}" >> $GITHUB_STEP_SUMMARY
        echo "üîÑ **Comparison Model**: ${{ env.COMPARISON_MODEL }}" >> $GITHUB_STEP_SUMMARY
        echo "üìÅ **Location**: \`docs/ai-advanced/\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üìä Generated Reports" >> $GITHUB_STEP_SUMMARY
        find docs/ai-advanced -name "*.md" -exec basename {} \; | sort | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üéØ Advanced Features Available" >> $GITHUB_STEP_SUMMARY
        echo "- **Multi-Model Comparison**: Compare multiple AI models on the same task" >> $GITHUB_STEP_SUMMARY
        echo "- **Code Quality Analysis**: Comprehensive code quality assessment" >> $GITHUB_STEP_SUMMARY
        echo "- **Security Audit**: AI-powered security vulnerability analysis" >> $GITHUB_STEP_SUMMARY
        echo "- **Performance Optimization**: Performance bottleneck identification" >> $GITHUB_STEP_SUMMARY
        echo "- **Architecture Review**: System architecture analysis and recommendations" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "üéâ **Advanced AI features are working perfectly with GitHub Models!**" >> $GITHUB_STEP_SUMMARY